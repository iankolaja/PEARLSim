{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51524e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pearlsim.ml_utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a032d",
   "metadata": {},
   "source": [
    "# Extract data from Serpent detector files\n",
    "We can use the read_det_file function from ml_utilities to parse all of the detector files we have in the training data directory to create one pair of unified features/target dataframes.\n",
    "\n",
    "Sometimes the file(s) provided will have really high uncertainty. This will absolutely limit your model's accuracy, so don't be disheartened until I get you more accurate data, which can take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c577a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"training_data/burnup_features.csv\", index_col=0)\n",
    "targets = pd.read_csv(\"training_data/burnup_target.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8995a76",
   "metadata": {},
   "source": [
    "Our features include the radius and height of the pebble-based detector. It also includes every bin of the core flux map. The gFHR model is divided into 12 energy groups and has 4 radial divisions, each divided into 10 separate axial zones. Normally you would need to volume-weight these flux values, and deal with the somewhat complicated indexing scheme to sort out which is which. We don't need to bother here, since they're all going to be standardized anyways and the model will make its own inferences about the spatial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7de2c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.004355\n",
       "1    0.004353\n",
       "2    0.003573\n",
       "3    0.004670\n",
       "4    0.004559\n",
       "5    0.004135\n",
       "6    0.003781\n",
       "7    0.003771\n",
       "8    0.004052\n",
       "9    0.003465\n",
       "Name: 92235<lib>, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['92235<lib>'].iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0015444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.004355\n",
       "1    0.004353\n",
       "2    0.003573\n",
       "3    0.004669\n",
       "4    0.004559\n",
       "5    0.004134\n",
       "6    0.003781\n",
       "7    0.003770\n",
       "8    0.004052\n",
       "9    0.003465\n",
       "Name: 92235<lib>, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets['92235<lib>'].iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60697270",
   "metadata": {},
   "source": [
    "# Data Standardization\n",
    "Simple standardization is performed here along each column. You might want to consider looking into log standardization, but it didn't seem to help much for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98c146f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 433)\n",
      "(80, 589)\n",
      "(20, 433)\n",
      "(20, 589)\n"
     ]
    }
   ],
   "source": [
    "train_split = 0.8\n",
    "np.random.seed(42)\n",
    "\n",
    "def standardize(raw_data, mean=None, std=None, axis=0):\n",
    "    if mean is None:\n",
    "        mean = np.mean(raw_data, axis = axis)\n",
    "    if std is None:\n",
    "        std = np.std(raw_data, axis = axis)\n",
    "        std[ std==0 ] = 0.1\n",
    "    result = (raw_data - mean) / std\n",
    "    return result, mean, std\n",
    "\n",
    "def unstandardize(standardized_data, mean, std):\n",
    "    raw_data = (standardized_data*std)+mean\n",
    "    return raw_data\n",
    "\n",
    "\n",
    "num_data = len(features)\n",
    "training_size = int(num_data*train_split)\n",
    "testing_size = num_data - training_size\n",
    "data_indices = np.arange(num_data)\n",
    "training_indices = np.random.choice(num_data, training_size, replace=False)\n",
    "testing_indices = data_indices[np.in1d(data_indices, training_indices, invert=True)]\n",
    "\n",
    "training_data, data_mean, data_std = standardize(features.iloc[training_indices])\n",
    "training_target, target_mean, target_std = standardize(targets.iloc[training_indices])\n",
    "testing_data, _, _  = standardize(features.iloc[testing_indices], mean=data_mean, std=data_std)\n",
    "testing_target, _, _  = standardize(targets.iloc[testing_indices], mean=target_mean, std=target_std)\n",
    "\n",
    "print(np.shape(training_data))\n",
    "print(np.shape(training_target))\n",
    "print(np.shape(testing_data))\n",
    "print(np.shape(testing_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d584f38",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "I threw together a quick RFR model and got some results. You're free to change to any other type of model, as long as its something I can save and load into other modules. Things to try:\n",
    "- Properly using cross validation\n",
    "- Tuning the hyper parameters\n",
    "- Trying a different model, probably a neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd06d727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFR score: -0.05276871866241244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/software/sl-7.x86_64/modules/langs/python/3.7/lib/python3.7/site-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "best_params = {'max_depth': 10, \n",
    "               'n_estimators': 1000, \n",
    "               'n_jobs': 14,} # Set to your number of cores\n",
    "rfr_model = RandomForestRegressor(random_state=0)\n",
    "rfr_model.set_params(**best_params)\n",
    "rfr_model.fit(training_data, training_target)\n",
    "rfr_model_test_score = rfr_model.score(testing_data, testing_target)\n",
    "print(f\"RFR score: {rfr_model_test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5783c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
